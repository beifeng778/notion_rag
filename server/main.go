// main.go
package main

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io/fs"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/tmc/langchaingo/embeddings"
	"github.com/tmc/langchaingo/llms"
	"github.com/tmc/langchaingo/llms/openai"
	"github.com/tmc/langchaingo/prompts"
	"github.com/tmc/langchaingo/schema"
	"github.com/tmc/langchaingo/textsplitter"
	"github.com/tmc/langchaingo/vectorstores/chroma"
)

// CustomEmbedder å®ç° embeddings.Embedder
type CustomEmbedder struct {
	Endpoint string
}

func (e *CustomEmbedder) EmbedDocuments(ctx context.Context, texts []string) ([][]float32, error) {
	return e.embed(texts)
}

func (e *CustomEmbedder) EmbedQuery(ctx context.Context, text string) ([]float32, error) {
	embs, err := e.embed([]string{text})
	if err != nil {
		return nil, err
	}
	return embs[0], nil
}

func (e *CustomEmbedder) embed(texts []string) ([][]float32, error) {
	reqBody, _ := json.Marshal(map[string][]string{"texts": texts})
	resp, err := http.Post(e.Endpoint, "application/json", bytes.NewBuffer(reqBody))
	if err != nil {
		return nil, fmt.Errorf("failed to call embed server: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("embed server returned status: %d", resp.StatusCode)
	}

	var result struct {
		Embeddings [][]float32 `json:"embeddings"`
	}
	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, fmt.Errorf("failed to decode response: %w", err)
	}
	return result.Embeddings, nil
}

var _ embeddings.Embedder = &CustomEmbedder{}

// loadMarkdownFiles é€’å½’åŠ è½½ç›®å½•ä¸‹æ‰€æœ‰ .md æ–‡ä»¶
func loadMarkdownFiles(dir string) ([]string, error) {
	var files []string
	err := filepath.WalkDir(dir, func(path string, d fs.DirEntry, err error) error {
		if err != nil {
			return err
		}
		if !d.IsDir() && strings.HasSuffix(strings.ToLower(d.Name()), ".md") {
			content, err := os.ReadFile(path)
			if err != nil {
				return err
			}
			files = append(files, string(content))
		}
		return nil
	})
	return files, err
}

func main() {
	ctx := context.Background()

	// æ£€æŸ¥æ–‡æ¡£ç›®å½•
	if _, err := os.Stat("../notion_docs"); os.IsNotExist(err) {
		log.Fatal("âŒ è¯·å°† Notion Markdown æ–‡ä»¶æ”¾åœ¨ ./notion_docs ç›®å½•ä¸­")
	}

	// === 1. åŠ è½½æ‰€æœ‰ .md æ–‡ä»¶å†…å®¹ ===
	fmt.Println("ğŸ“‚ åŠ è½½ Notion æ–‡æ¡£...")
	rawContents, err := loadMarkdownFiles("../notion_docs")
	if err != nil {
		log.Fatal("åŠ è½½æ–‡æ¡£å¤±è´¥:", err)
	}
	fmt.Printf("âœ… æˆåŠŸåŠ è½½ %d ä¸ªæ–‡ä»¶\n", len(rawContents))

	// === 2. ä½¿ç”¨ Markdown åˆ†å—å™¨åˆ†å— ===
	splitter := textsplitter.NewRecursiveCharacter(
		textsplitter.WithChunkSize(400),
		textsplitter.WithChunkOverlap(50),
		textsplitter.WithSeparators([]string{"\n\n", "\n", " ", ""}),
	)

	var allChunks []schema.Document
	for _, content := range rawContents {
		// å…ˆç”¨ Markdown splitter åˆæ­¥å¤„ç†ï¼ˆå¯é€‰ï¼‰
		mdSplitter := textsplitter.NewMarkdownTextSplitter()
		mdDocs, err := mdSplitter.SplitText(content)
		if err != nil {
			log.Printf("Warning: Markdown split failed, using raw text")
			mdDocs = []string{content}
		}

		// å†ç”¨é€’å½’åˆ†å—
		for _, mdChunk := range mdDocs {
			chunks, err := splitter.SplitText(mdChunk)
			if err != nil {
				continue
			}
			for _, chunk := range chunks {
				if strings.TrimSpace(chunk) != "" {
					allChunks = append(allChunks, schema.Document{PageContent: chunk})
				}
			}
		}
	}
	fmt.Printf("âœ‚ï¸  åˆ†å—å®Œæˆï¼Œå…± %d ä¸ªæ–‡æœ¬å—\n", len(allChunks))

	// === 3. åˆ›å»º Embedder ===
	embedder := &CustomEmbedder{Endpoint: "http://localhost:8081/embed"}

	// === 4. è¿æ¥ Chroma ===
	fmt.Println("ğŸ”— è¿æ¥ Chroma å‘é‡æ•°æ®åº“...")
	store, err := chroma.New(
		chroma.WithNameSpace("notion_rag"),
		chroma.WithEmbedder(embedder),
		chroma.WithChromaURL("http://localhost:8000"),
	)
	if err != nil {
		log.Fatal("è¿æ¥ Chroma å¤±è´¥:", err)
	}

	// === 5. å¯¼å…¥æ–‡æ¡£ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰===
	// ç®€å•ç­–ç•¥ï¼šå°è¯•æ£€ç´¢ï¼Œå¤±è´¥åˆ™è®¤ä¸ºæ˜¯é¦–æ¬¡
	fmt.Println("ğŸ“¥ æ£€æŸ¥æ˜¯å¦éœ€è¦å¯¼å…¥æ–‡æ¡£...")
	_, err = store.SimilaritySearch(ctx, "hello", 1)
	if err != nil && (strings.Contains(err.Error(), "not found") || strings.Contains(err.Error(), "collection")) {
		fmt.Println("ğŸ†• é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨å¯¼å…¥æ–‡æ¡£...")
		_, err := store.AddDocuments(ctx, allChunks)
		if err != nil {
			log.Printf("è­¦å‘Šï¼šå¯¼å…¥æ–‡æ¡£æ—¶å‡ºç°é”™è¯¯: %v", err)
		}
		fmt.Println("âœ… æ–‡æ¡£å¯¼å…¥å®Œæˆï¼")
		time.Sleep(2 * time.Second)
	} else {
		fmt.Println("âœ… æ–‡æ¡£å·²å­˜åœ¨ï¼Œè·³è¿‡å¯¼å…¥")
	}

	// === 6. åˆå§‹åŒ– LLM ===
	// éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ MOONSHOT_API_KEY
	fmt.Println("ğŸ§  åˆå§‹åŒ– LLM (Kimi K2)...")
	apiKey := os.Getenv("MOONSHOT_API_KEY")
	if apiKey == "" {
		log.Fatal("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ MOONSHOT_API_KEY")
	}
	llm, err := openai.New(
		openai.WithToken(apiKey),
		openai.WithBaseURL("https://api.moonshot.ai/v1"),
		openai.WithModel("kimi-k2-0711-preview"),
	)
	if err != nil {
		log.Fatal("åˆå§‹åŒ– LLM å¤±è´¥:", err)
	}

	// === 7. æé—®ä¸æ£€ç´¢ ===
	question := "å¦‚ä½•é«˜æ•ˆè¿›è¡Œé¡¹ç›®å¤ç›˜ï¼Ÿ"
	fmt.Printf("\nâ“ é—®é¢˜: %s\n", question)

	relevantDocs, err := store.SimilaritySearch(ctx, question, 3)
	if err != nil {
		log.Fatal("æ£€ç´¢å¤±è´¥:", err)
	}

	context := ""
	for i, doc := range relevantDocs {
		context += fmt.Sprintf("ç‰‡æ®µ %d: %s\n\n", i+1, doc.PageContent)
	}

	// æ„é€  prompt
	promptTemplate := `ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœä¸çŸ¥é“ï¼Œè¯·è¯´â€œæ— æ³•å›ç­”â€ã€‚

ä¸Šä¸‹æ–‡ï¼š
{{.context}}

é—®é¢˜ï¼š{{.question}}

å›ç­”ï¼š`
	prompt := prompts.NewPromptTemplate(promptTemplate, []string{"context", "question"})
	promptVal, _ := prompt.Format(map[string]any{
		"context":  context,
		"question": question,
	})

	// è°ƒç”¨ LLMï¼ˆæ³¨æ„ï¼šWithTemperature æ˜¯ llms åŒ…çš„é€‰é¡¹ï¼‰
	answer, err := llm.Call(ctx, promptVal, llms.WithTemperature(0.3)) // âœ… ä¿®æ­£
	if err != nil {
		log.Fatal("LLM è°ƒç”¨å¤±è´¥:", err)
	}

	fmt.Println("\nğŸ“š æ£€ç´¢ç»“æœ:")
	fmt.Println(context)
	fmt.Println("ğŸ¤– å›ç­”:")
	fmt.Println(answer)
}
